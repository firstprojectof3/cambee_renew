# app/services/llm.py
import os, json
from typing import Optional, Dict
from openai import OpenAI

def _load_system_prompt() -> str:
    """
    ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì£¼ì…í•˜ëŠ” ìš°ì„ ìˆœìœ„:
    1) SYSTEM_PROMPT_FILE ê²½ë¡œì— ìˆëŠ” íŒŒì¼ ë‚´ìš©
    2) SYSTEM_PROMPT í™˜ê²½ë³€ìˆ˜
    3) ê¸°ë³¸ê°’(ì„ì‹œ í”„ë¡¬í”„íŠ¸)
    ğŸ‘‰ íŒ€ì˜ ê³µì‹ í”„ë¡¬í”„íŠ¸ë¥¼ íŒŒì¼/í™˜ê²½ë³€ìˆ˜ë¡œ ë„£ì–´ ì“°ë©´ ëœë‹¤.
    """
    path = os.getenv("SYSTEM_PROMPT_FILE")
    if path and os.path.exists(path):
        try:
            return open(path, "r", encoding="utf-8").read()
        except Exception:
            pass
    return os.getenv("SYSTEM_PROMPT", "").strip() or (
        "ì—­í• : ëŒ€í•™ í–‰ì •/ê³µì§€/í•™ì‚¬ ë„ìš°ë¯¸.\n"
        "ê·œì¹™: í•­ìƒ í•œêµ­ì–´ë¡œ ê°„ê²°/ì •í™•í•˜ê²Œ ë‹µí•˜ê³ , JSONë§Œ ë°˜í™˜.\n"
        'ì¶œë ¥ ìŠ¤í‚¤ë§ˆ: {"title": str, "link": str|null, "summary": str}'
    )

_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
_SYSTEM = _load_system_prompt()

def _parse_json(content: str) -> Dict[str, Optional[str]]:
    try:
        data = json.loads(content or "{}")
    except Exception:
        data = {}
    title = data.get("title") or "ìë™ ìƒì„±ëœ ìš”ì•½"
    link = data.get("link")
    summary = data.get("summary") or ""
    return {
        "title": str(title),
        "link": (str(link) if link else None),
        "summary": str(summary),
    }

def gpt_answer(question: str, context: Optional[str] = None) -> Dict[str, Optional[str]]:
    """
    ë‹¨ì¼ LLM í˜¸ì¶œë¡œ JSON ì‘ë‹µ ìƒì„±. (ì™¸ë¶€ ê²€ìƒ‰ ì—†ìŒ)
    í•„ìš”í•˜ë©´ contextë¡œ ì¶”ê°€ íŒíŠ¸ë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆìŒ.
    """
    messages = [
        {"role": "system", "content": _SYSTEM},
        {"role": "user", "content": (f"ì§ˆë¬¸: {question}\n\nì¶”ê°€ì»¨í…ìŠ¤íŠ¸:\n{context}" if context else question)},
        {"role": "user", "content": 'ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”: {"title": str, "link": str|null, "summary": str}'},
    ]
    resp = _client.chat.completions.create(
        model=_MODEL,
        messages=messages,
        response_format={"type": "json_object"},
        temperature=float(os.getenv("OPENAI_TEMPERATURE", "0.2")),
        timeout=60,
    )
    return _parse_json(resp.choices[0].message.content)
